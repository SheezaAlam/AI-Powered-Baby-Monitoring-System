
About Project 
AngelCam is an AI-powered baby monitoring system that uses object detection to identify and track babies in surveillance video footage. If a baby exits a defined safe zone, the system raises an alert. This solution is ideal for busy parents and can be integrated into nanny cams or smart surveillance systems. 
Abstract 
AngelCam is an AI-based object detection and alert system aimed at monitoring babies in real-time through surveillance feeds. The goal is to reduce accidents by alerting parents or caretakers when a baby moves out of a predefined safe zone. The system is trained using a custom-labeled dataset from Roboflow and employs YOLOv5 for baby detection. After detecting a baby in video frames, the system continuously tracks its position and displays alerts if it crosses the designated boundary. With OpenCV and Python integration, AngelCam outputs alert-enabled videos. This project can be extended to integrate audio alerts and smart home compatibility. 
 
Introduction 
Background / Motivation 
Busy parents often leave babies unattended in nurseries where they may wake up and crawl out of their crib, leading to injuries. A smart surveillance system that can monitor baby movement in real-time can prevent such incidents. 
Problem Statement 
To detect and track a baby in real-time video. To trigger an alert if the baby moves outside a predefined safe area. 
 
Objectives 
To develop an AI system capable of detecting and tracking babies in video streams and alerting caretakers if the baby exits a designated area. 
 
Scope of the Project 
The system will focus on using object detection (YOLOv5) to recognize babies in surveillance videos. It includes real-time tracking and zone-based alert mechanisms. Although hardware integration is not part of this scope, the solution can later be connected to nanny cams and smart home systems. 
 
Significance 
Prevent baby injuries due to unattended movement 
Enable intelligent nursery surveillance 
Provide an open-source solution for developers 
Improve safety in smart homes 


 
Literature Review 
Redmon, J., & Farhadi, A. (2018). YOLOv3: An Incremental Improvement. The authors introduce YOLOv3, a real-time object detection system that balances speed and accuracy, laying the foundation for YOLOv5. 
Bochkovskiy, A., Wang, C., & Liao, H. Y. M. (2020). YOLOv4: Optimal Speed and Accuracy of Object Detection. This paper presents YOLOv4, focusing on efficiency for deployment. 
Joseph Redmon et al., You Only Look Once: Unified, Real-Time Object Detection. CVPR 2016. Introduces the original YOLO algorithm for fast object detection. 
Wang, X. et al. (2019). Dynamic video object detection using deep learning. Discusses applying object detection in videos, a direct use case for AngelCam. 
Chen, Y., Li, H., & Xiao, J. (2018). Multi-object tracking with neural networks. Focuses on object tracking, which enhances detection systems. 
 
Gaps in Current Solutions 
Existing System 
Limitation 
 Traditional Cams 
 No AI detection 
 Basic Motion Detection 
 High false alarms 
 Expensive AI systems 
 Not open source 


Methodology / Proposed System 
Algorithm / Model 
YOLOv5: Used for real-time object detection due to its speed and accuracy. 
Dataset Description 
Custom baby detection dataset from Roboflow with bounding boxes for object detection. 
Source: https://universe.roboflow.com 
1 class: 'baby' 
Labeled images for training and validation 
Data Preprocessing Steps 
Downloaded and unzipped dataset 
Created YAML config file for training 
Normalized image dimensions 
Model Architecture 
Input video → YOLOv5 Detection → Safe Zone Check → Alert Display → Output Video 
Tools and Technologies 
Google Colab 
Python 
OpenCV 
Ultralytics YOLOv5 
 
Implementation 
Workflow 
Install dependencies 
Download dataset from Roboflow 
Train YOLOv5 model 
Convert training images to video 
Detect baby in video using trained model 
Check if baby is inside safe zone 
Add alert on frame if outside 
Save final video 
Code structure / modules 
train.py: YOLOv5 training script 
video_generator.py: Converts images to video 
alert_system.py: Applies detection and alert 
Key functions or pseudocode 
torch.hub.load('ultralytics/yolov5', 'custom', path='runs/train/exp/weights/best.pt') 
cv2.rectangle(...) to draw safe zone 
model.conf = 0.4 to set confidence threshold 
SAFE_ZONE = (...) defines monitoring region 


 Results and Evaluation 
Performance Metrics 
Accuracy: 90% detection in ideal conditions 
Confidence threshold: 0.4 (balanced sensitivity) 
Graphs 
 
Conclusion 
Summary 
AngelCam successfully detects babies in video frames and raises alerts when they move outside a predefined zone. It leverages YOLOv5 and OpenCV for real-time object detection and alerting. 
Achievements 
Trained custom baby detection model 
Implemented real-time video detection 
Created visual alert mechanism 
Real-world Application Potential 
Can be used in nurseries 
Add-on to smart cameras 
Integrate with mobile apps for alerts 
 
 
Project Code 
python-mini-projects/AI_Project_Final.ipynb at main · SheezaAlam/python-mini-projects 
References 
Redmon, J., & Farhadi, A. (2018). YOLOv3: An Incremental Improvement. 
Bochkovskiy, A., et al. (2020). YOLOv4: Optimal Speed and Accuracy. 
Wang, X., et al. (2019). Deep Learning for Video Object Detection. 
Chen, Y., et al. (2018). Multi-Object Tracking with Neural Networks. 
Roboflow Dataset. Retrieved from https://universe.roboflow.com 
Ultralytics YOLOv5 GitHub. https://github.com/ultralytics/yolov5 
 


